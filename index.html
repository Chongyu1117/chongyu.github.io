<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Chongyu Qu</title>

    <meta name="author" content="Chongyu Qu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/JHU_icon.jpg" type="image/png">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Chongyu Qu
                </p>
                <p>
                  2023.3 - present, currently, I'm a research assistant at <a href="https://ccvl.jhu.edu/">CCVL (Computational Cognition, Vision, and Learning) Lab</a> at <a href="https://www.jhu.edu/">Johns Hopkins University</a>, under the advisement of <a href="https://www.cs.jhu.edu/~ayuille/">Prof. Alan L.Yuille</a> and <a href="https://www.zongweiz.com/">Dr. Zongwei Zhou</a>.
                </p>
                <p>
                  2020.8 - 2022.5, I was a master student at <a href="https://www.bme.jhu.edu/">Department of Biomedical Engineering</a> at <a href="https://www.jhu.edu/">Johns Hopkins University</a>
                </p>
                <p>
                  2017.8 - 2020.5, I was an undergraduate student at <a href="https://www.osu.edu/">The Ohio State University</a> with a major in <a href="https://artsandsciences.osu.edu/academics/programs/majors/biology-ba-bs">Biology</a>
                </p>
                <p>
                  I am looking for Ph.D. positions in computer vision and medical image analysis in Fall 2024. If you are interested in my background and have some available positions, please let me know.
                </p>

                <p style="text-align:center">
                  <a href="mailto:cyqu17@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/ChongyuQu-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=5irnqbkAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Chongyu1117">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/ChongyuQu.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/ChongyuQu.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <hr>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research Statement</h2>
                <p>
                  My research interests lie in the intersection of <strong>computer vision</strong> and <strong>medical image analysis</strong>. My current focus is on developing a robust <strong>medical foundation model</strong> with adaptability to various downstream applications. 
                  The ultimate objective is to advance innovations in <strong>computer-aided diagnosis</strong>. This involves assisting experts in acquiring a more comprehensive understanding of the human body, delivering precise diagnoses, and enabling early detection.
                </p>
                <p>
                  Towards this goal, I have (1) created a <strong>composite dataset</strong> that unified medical datasets from at least 26 different hospitals worldwide. This dataset provides 8,448 CT volumes with per-voxel annotations of eight organs. 
                  I have also (2) proposed an <strong>active learning procedure</strong> that can generate an attention map to highlight the regions to be revised by radiologists, reducing the annotation time from 30.8 years to three weeks. This strategy can scale up annotations quickly for creating medical datasets or even natural imaging datasets.
                </p>
              </td>
            </tr>
          </tbody></table>
          <hr>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>News</h2>
              <ul>
                <li><strong>[Oct. 2023]</strong> One papers is accepted to <b>NeurIPS 2023</b>.
                <li><strong>[Jul. 2023]</strong> Our abstract is accepted to <b>RSNA 2023 (Oral Presentation)</b>.
  
              </ul>
            </td>
          </tr>
        </tbody></table>
        <hr>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <h2>Publications</h2>
          </td>
        </tr>
      </tbody></table>
      <table
          style="width:110%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
              <td style="padding:20px;width:35%;vertical-align:left">
                <div><img style="width:100%;max-width:100%" src="images/AbdomenAtlas-8k.png"></div>
              </td>
              <td style="padding:30px;width:60%;vertical-align:middle">
                  <papertitle><strong>AbdomenAtlas-8K: Annotating 8,000 CT Volumes for
                    Multi-Organ Segmentation in Three Weeks</strong></papertitle>
                <br>
                <br>
                <strong>Chongyu Qu</strong>, 
                <a href="https://scholar.google.com/citations?user=hUMQfb4AAAAJ&hl=en">Tiezheng Zhang</a>,
                <a href="https://scholar.google.com/citations?user=7-7-BF0AAAAJ&hl=en">Hualin Qiao</a>,
                <a href="https://scholar.google.com.hk/citations?user=k05bkIEAAAAJ&hl=zh-CN">Jie Liu</a>,
                <a href="https://scholar.google.com/citations?user=0xheliUAAAAJ&hl=en">Yucheng Tang</a>
                <a href="https://scholar.google.com/citations?user=FJ-huxgAAAAJ&hl=en">Alan L. Yuille</a>
                <a href="https://scholar.google.com/citations?user=JVOeczAAAAAJ&hl=en">Zongwei Zhou*</a>

                <br>
                Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2023
                <br>
                <a href="https://arxiv.org/pdf/2305.09666.pdf">[paper]</a>
                <a href="https://github.com/MrGiovanni/AbdomenAtlas/tree/main">[code]</a>
                <a href="data/ChongyuNIPS2023.bib">[bibtex]</a>
                <p>
                  This paper proposes an active learning procedure to expedite the annotation process for organ segmentation and creates the largest multi-organ dataset (by far) with the spleen, liver, kidneys, stomach, gallbladder, pancreas, aorta, and IVC annotated in <strong>8,448</strong> CT volumes, equating to <strong>3.2 million</strong> slices.
                </p>
              </td>
            </tr>
      </tbody></table>
      
      <hr>
      
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:0px">
            <br>
            <p style="text-align:right;">Webpage template borrowed from <a href="https://jonbarron.info/">Jon Barron</a></p>
          </td>
        </tr>
      </tbody></table>


        
          
        </td>
      </tr>
    </table>
  </body>
</html>
